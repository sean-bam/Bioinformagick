{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twenty-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from Bio import AlignIO\n",
    "from Bio.Align import substitution_matrices\n",
    "#from Bio.Seq import Seq\n",
    "#from Bio.SeqRecord import SeqRecord\n",
    "#from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-proceeding",
   "metadata": {},
   "source": [
    "# MSA filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-throat",
   "metadata": {},
   "source": [
    "**How does Yuri filter MSAs?**\n",
    "\n",
    "The main filtering done in his scripts/phylogenetic reconstruction is to:\n",
    "1) remove gaps\n",
    "2) remove low \"homogeneity\" positions\n",
    "3) intelligently add a consensus sequence\n",
    "\n",
    "All of this involves sequence weighting. Sequence weighting is typically performed in MSAs to downweight highly redundant sequences and upweight diverse sequences. There are tree-based and distance-based weighting schemes. According to Henikoff & Henikoff 1994 [paper](https://doi.org/10.1016/0022-2836(94)90032-9), for both schemes, \n",
    ">\"the weight assigned to a sequence is a measure of the distance between the sequence and a root or generalized sequence. Each distance is based on the entire sequence in question. However, the seq weight are typically applied to PSSMs in which each position is considered independently\".\n",
    "\n",
    "Both `sr_filter` and PSI-BLAST use Henikoff & Henikoff 1994 (HH94). According to this recent [paper](https://doi.org/10.1186/s12859-021-04183-8), their summary of the method is the following:\n",
    ">the score of a sequence is the average of the scores of each position of the sequence, the score of a position being 1/rd, with r the number of different characters at the considered alignment column and d the number of times the character of the considered sequence and position appears in the considered alignment column. The idea of this weighting scheme is to give equal weight to all characters observed at one alignment column, dividing this weight equally among those sequences sharing that character at that position.\n",
    "\n",
    "What they fail to mention from the Henikoff paper is the part about the consensus:\n",
    ">\"for every position of the alignment, the PSSM entry for each residue was the sequence- weighted observed frequency of that residue divided by its expected frequency tabulated from SWISS-PROT\".\n",
    "\n",
    "I asked Yuri how he filters MSAs. He told me to look at methods section 2.3 of a [paper of his](https://doi.org/10.1093/ve/veab015) and replied:\n",
    ">Basically, the \"best\" amino acid is the one with the highest score (sr_filter has BLOSUM62 built-in) against the alignment column, calculated with sequence weights. Homogeneity prorates this score between the maximum (strictly homogeneous) and the non-pathological minimum (random assortment of amino acids). Consensus amino acid is registered when the homogeneity is above the threshold, otherwise it's set to \"X\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-concentrate",
   "metadata": {},
   "source": [
    "In summary\n",
    "1. Calculate HH94 score of a seq in an MSA\n",
    "2. Calculate the Q score of an AA (x) in an MSA column as Qx = (HH94 score) * (blosum62 score for X against all AAs)\n",
    "     - For each position in the MSA, an aligned AA is given a frequency score that is incremented by the HH94 score of the sequence. If the position is a gap, all AAs are possible, so each AA frequency is incremented by their default frequency in swiss prot*HH94 score. What we are left with is a vector of 20 amino acids and their frequencies for each column, where the frequencies of aligned AAs are typically much higher than their background swiss prot frequency.\n",
    "3. The consensus AA for that position is the AA with the highest Qx score\n",
    "4. Calculate the expectation of the score of an MSA column against a randomly selected AA (R) as Qr = (vector of relative frequencies of AAs) * Qscore\n",
    "5. Calculate the homogeneity of an MSA column as H = (consensus - expectation) / (blosum score - expectation)\n",
    "6. Keep/discar consensus AA depending on threshold \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-quantum",
   "metadata": {},
   "source": [
    "Pseudocode\n",
    "```\n",
    "#get HH94 weights of sequences\n",
    "for seq in MSA:\n",
    "    calculate hh94 score\n",
    "    \n",
    "#get an expectation of AA substitutions\n",
    "for AA1 (n=20):\n",
    " for AA2 (n=20):\n",
    "    AAexpected = swiss_prot_frequency * blosum62(AA1xAA2)\n",
    "\n",
    "#column specific frequencies\n",
    "for col in msa:\n",
    "    if AA = \"-\":\n",
    "        ngaps += HH94_sequence_weight\n",
    "    for seq in msa:\n",
    "        if aligned_AA:\n",
    "            AAfreq += HH94_sequence_weight\n",
    "        elif:\n",
    "            AAfreq += swiss_prot_frequency x HH94_sequence_weight\n",
    "            \n",
    "        #consensus\n",
    "        for AA1(n=20):\n",
    "            for AA2(n=20):\n",
    "                AA1_weight += blosum62(AA1xAA2) * AAfreq(AA2)\n",
    "                \n",
    "        bestAA = argmax(AA1_weights); AA1_weights > 0\n",
    "        \n",
    "        #homogeneity\n",
    "        if bestAA/nseqs > AAexpected:\n",
    "            homogeneity = (bestAA / nseqs - bestAAexpected) / (blosum62(bestAAxbestAA) - bestAAexpected)\n",
    "            \n",
    "        if ngaps <= nseq*grcon:\n",
    "            if homogeneity > homo_cutoff\n",
    "                consensusAA = bestAA\n",
    "         else:\n",
    "             consensusAA = X\n",
    "            \n",
    "                \n",
    "```\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-olympus",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-duplicate",
   "metadata": {},
   "source": [
    "### background tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables_for_msa_filtering():\n",
    "    \n",
    "    #set a background frequency of AAs\n",
    "    background_aa_freq = {\n",
    "                            \"A\" : 0.07422,\n",
    "                            \"C\" : 0.02469,\n",
    "                            \"D\" : 0.05363,\n",
    "                            \"E\" : 0.05431,\n",
    "                            \"F\" : 0.04742,\n",
    "                            \"G\" : 0.07415,\n",
    "                            \"H\" : 0.02621,\n",
    "                            \"I\" : 0.06792,\n",
    "                            \"K\" : 0.05816,\n",
    "                            \"L\" : 0.09891,\n",
    "                            \"M\" : 0.02499,\n",
    "                            \"N\" : 0.04465,\n",
    "                            \"P\" : 0.03854,\n",
    "                            \"Q\" : 0.03426,\n",
    "                            \"R\" : 0.05161,\n",
    "                            \"S\" : 0.05723,\n",
    "                            \"T\" : 0.05089,\n",
    "                            \"V\" : 0.07292,\n",
    "                            \"W\" : 0.01303,\n",
    "                            \"Y\" : 0.03228,\n",
    "                         }\n",
    "        \n",
    "    #get a blosum62 matrix\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "\n",
    "    #set a expectation of AAs\n",
    "    #expectation_aa = {}\n",
    "    #for aa1 in background_aa_freq.keys():\n",
    "    #    expectation_aa[aa1] = 0\n",
    "    #    for aa2 in background_aa_freq.keys():\n",
    "    #        expectation_aa[aa1] = expectation_aa[aa1] + blosum62[aa1,aa2]*background_aa_freq[aa2]\n",
    "    \n",
    "    expectation_aa = aa_freq_to_score(background_aa_freq)\n",
    "\n",
    "    return background_aa_freq, blosum62, expectation_aa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trying-advertiser",
   "metadata": {},
   "source": [
    "### AA frequency to score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "removed-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aa_freq_to_score(col_aa_frq):\n",
    "    \"\"\"\n",
    "    expects a dictionary of AA : frequency\n",
    "    returns a dictionary of AA : score\n",
    "    \n",
    "    score is sum of blosum62 scores of an index AA versus all other AAs\n",
    "    \"\"\"\n",
    "    #set all AA weights as zero\n",
    "    weights = {}\n",
    "    for aa in col_aa_frq.keys():\n",
    "        weights[aa] = 0\n",
    "        \n",
    "    #get a blosum62 matrix\n",
    "    blosum62 = substitution_matrices.load(\"BLOSUM62\")\n",
    "    \n",
    "    #assign weights to each AA\n",
    "    for aa1 in col_aa_frq.keys():\n",
    "        for aa2 in col_aa_frq.keys():\n",
    "            weights[aa1] = weights[aa1] + (blosum62[aa1,aa2] * col_aa_frq[aa2])\n",
    "            #print(f\"AA1 is {aa1}, AA2 is {aa2}, frequency of AA2 is {col_aa_frq[aa2]}, blosum62 of {aa1}{aa2} is {blosum62[aa1,aa2]}, updating weight of AA1 to {weights[aa1]}\")\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-shelter",
   "metadata": {},
   "source": [
    "### msa_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "healthy-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deprecated\n",
    "def aln_to_df(aln, msa_format='fasta'):\n",
    "    \"\"\"\n",
    "    convertsa  biopython alignment object into a pandas dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = [rec.id for rec in aln]\n",
    "    seqs = [list(rec) for rec in aln]\n",
    "    df = pd.DataFrame.from_records(seqs, index = headers).astype('str')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "electronic-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fa_to_df(fa, is_msa=False):\n",
    "    \"\"\"\n",
    "    Converts a fasta-formatted file to a pandas dataframe\n",
    "    \"\"\"\n",
    "    with open(fa) as infile:\n",
    "        headers = []\n",
    "        seqs = []\n",
    "        for line in infile:\n",
    "            if line.startswith(\">\"):\n",
    "                header = line.strip(\">\").split()[0]\n",
    "                headers.append(header)\n",
    "            else:\n",
    "                seq = list(line.strip())\n",
    "                seqs.append(seq)\n",
    "        \n",
    "    df = pd.DataFrame.from_records(seqs, index = headers)\n",
    "    \n",
    "    #check to make sure the MSA is aligned properly\n",
    "    if is_msa:\n",
    "        assert df.isna().sum().sum() == 0, f\"All sequences must be the same length\"\n",
    "   \n",
    "    return df\n",
    "\n",
    "def df_to_fa(df, output):\n",
    "    \"\"\"\n",
    "    converts a pandas dataframe of sequences to a fasta-formatted file\n",
    "    \"\"\"\n",
    "    \n",
    "    #combine the columns into a single string\n",
    "    series = df.T.apply(\"\".join)\n",
    "    \n",
    "    #write the output\n",
    "    with open(output, 'w') as o:\n",
    "        for header, seq in series.items():\n",
    "            print(f\">{header}\", seq, sep = '\\n', file = o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-external",
   "metadata": {},
   "source": [
    "### get_gap_cols_from_msa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "alternative-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gap_cols_from_msa(df, grcut=1):\n",
    "    \"\"\"\n",
    "    -grcut = no more than r fraction of gaps\n",
    "    \n",
    "    returns a list of columns that are more than r fraction of gaps\n",
    "    \"\"\"\n",
    "    #df = msa_to_df(msa)\n",
    "    num_seqs, num_columns = df.shape\n",
    "    EPSILON = 1e-6\n",
    "\n",
    "    #calculate the minimum number of non-NA values per column\n",
    "    max_gaps_in_column = round((num_seqs * grcut) + EPSILON, 3)\n",
    "    \n",
    "\n",
    "    #convert gaps to NA, count how many NAs per column\n",
    "    gap_count_series = df.replace(\"-\", np.nan).isnull().sum()\n",
    "\n",
    "    #get columns where number of NAs is > max_gaps\n",
    "    gap_col_list = gap_count_series.loc[lambda s: s > max_gaps_in_column].index.tolist()\n",
    "    #df2 = df.loc[:, good_cols]\n",
    "    \n",
    "    ##RO\n",
    "    \n",
    "    return gap_col_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-designation",
   "metadata": {},
   "source": [
    "### calc_HH94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "private-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_HH94(df, grswe=0.51):\n",
    "    \"\"\"\n",
    "    - sequences have an initial weight of 1/nseq\n",
    "    - Calculates the score of a position in an MSA as 1/rd\n",
    "        r = # of dif characters (excluding gaps) in a column\n",
    "        d = number of times the character of the considered sequence \n",
    "        and position appears in the considered alignment column\n",
    "    \n",
    "    - columns in MSA that are >grswe fraction of gap positions are ignored\n",
    "    \n",
    "    - the scores of a sequence's aligned positions are added to its weight\n",
    "    \n",
    "    Returns a series object containing the sequence name and HH94 weight\n",
    "    \"\"\"\n",
    "    #df = msa_to_df(msa)\n",
    "    \n",
    "    #convert gaps to NA so they are not counted in the weights \n",
    "    df2 = df.replace(\"-\", np.nan)\n",
    "    \n",
    "    #get a list of gap columns that are more than grswe fraction of gaps\n",
    "    gap_cols = get_gap_cols_from_msa(df, grswe)\n",
    "    \n",
    "    #initial sequence weight is just 1 / nseq\n",
    "    initial_weight = 1 / len(df)\n",
    "\n",
    "    \n",
    "    colaa_weights_nest_dict = {}\n",
    "    for column in df2.columns:\n",
    "        if column not in gap_cols:\n",
    "        \n",
    "            #get a count of the frequency of each AA in the column\n",
    "            #by default, NAs (gaps) are not counted\n",
    "            col_series = df2[[column]].value_counts()\n",
    "\n",
    "            #calculate the AA weights in the column\n",
    "            #the length of the series is the number of unique AAs\n",
    "            colaa_weights = round(1 / (col_series * len(col_series)), 3)\n",
    "\n",
    "            #store the column-specific results in a dict of dict\n",
    "            colaa_weights_dict = colaa_weights.to_dict()\n",
    "            colaa_weights_nest_dict[column] = colaa_weights_dict\n",
    "\n",
    "    #replace the AAs in the MSA with their column-specific weights\n",
    "    df3 = df2.replace(colaa_weights_nest_dict)\n",
    "    \n",
    "    #for each sequence, sum all the values and add the initial wieght\n",
    "    hh94_series = df3.sum(axis = 1).round(3) + initial_weight\n",
    "    \n",
    "    #normalize\n",
    "    hh94_mean = hh94_series.mean()\n",
    "    if hh94_mean < 0:\n",
    "        hh94_mean = 1\n",
    "    hh94_norm = round(hh94_series / hh94_series.mean(), 4)\n",
    "    \n",
    "    #return a dictionary containing the sequence and its normalized weight\n",
    "    return hh94_norm.to_dict()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twelve-campbell",
   "metadata": {},
   "source": [
    "### col AA frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "engaging-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_aa_frequencies(column, hh94_scores, background_aa_freq):\n",
    "    \"\"\"\n",
    "    Accepts a dictionary or pandas series containing seq : aligned char\n",
    "    \n",
    "    calculates the column=specific AA weights, given HH94 scores of sequences\n",
    "    \n",
    "    returns a dictionary of AA : weight\n",
    "    \"\"\"\n",
    "    \n",
    "    #set all AA frequencies as zero\n",
    "    aafreq = {}\n",
    "    for aa in background_aa_freq.keys():\n",
    "        aafreq[aa] = 0\n",
    "    \n",
    "    #set gap score as zero\n",
    "    ngap = 0\n",
    "    \n",
    "    for seq,char in column.items():\n",
    "        if char == \"-\":\n",
    "            \n",
    "            #increment the background frequencies of all AAs\n",
    "            for aa, score in aafreq.items():\n",
    "                aafreq[aa] = aafreq[aa] + background_aa_freq[aa]*hh94_scores[seq]\n",
    "            \n",
    "            #increment the gap frequency \n",
    "            ngap += hh94_scores[seq]\n",
    "        else:\n",
    "            \n",
    "            aafreq[char] = aafreq[char] + hh94_scores[seq]\n",
    "    \n",
    "    #add in ngaps to the dict\n",
    "    aafreq[\"-\"] = ngap\n",
    "    \n",
    "    return aafreq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-princess",
   "metadata": {},
   "source": [
    "### best AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contrary-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_aa_and_score(aascores):\n",
    "    \"\"\"\n",
    "    Expects a dictionary of AA : score\n",
    "    Selects the AA with the highest score\n",
    "    \n",
    "    Returns AA and score\n",
    "    \"\"\"\n",
    "    \n",
    "    #get top AA and score, as a tuple\n",
    "    bestaa_tuple = max(aascores.items(), key = lambda k : k[1])\n",
    "    \n",
    "    return bestaa_tuple[0],bestaa_tuple[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-paste",
   "metadata": {},
   "source": [
    "### homogeneity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "normal-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_homogeneity(aa, score, nseqs, expectaascores, blosum62):\n",
    "    \"\"\"\n",
    "    calculates the homogeneity of a column in an MSA\n",
    "    homogeneity ranges from 0-1\n",
    "    \"\"\"\n",
    "    \n",
    "    homogeneity = (score/nseqs - expectaascores[aa]) / (blosum62[aa, aa] - expectaascores[aa])\n",
    "    return round(homogeneity, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-congo",
   "metadata": {},
   "source": [
    "### Consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "olympic-alarm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_consensus(bestaa, grcon, homo, hocon, ngaps, nseqs, ambiguousAA=\"X\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    #Default consensus is gap\n",
    "    caa = \"-\"\n",
    "\n",
    "    if ngaps <= nseqs * grcon:\n",
    "        if homo > hocon:\n",
    "            caa = bestaa\n",
    "        else:\n",
    "            caa = ambiguousAA\n",
    "\n",
    "    return caa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-montana",
   "metadata": {},
   "source": [
    "# manual pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "combined-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "background_aa_freq,blosum62,expectedAAscores = get_tables_for_msa_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "anticipated-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seq1</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>S</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq2</th>\n",
       "      <td>M</td>\n",
       "      <td>S</td>\n",
       "      <td>E</td>\n",
       "      <td>K</td>\n",
       "      <td>T</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq3</th>\n",
       "      <td>-</td>\n",
       "      <td>M</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>K</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seq4</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4  5\n",
       "seq1  M  S  E  D  S  I\n",
       "seq2  M  S  E  K  T  I\n",
       "seq3  -  M  E  D  K  I\n",
       "seq4  -  -  E  D  -  -"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = fa_to_df('tmp3.afa', is_msa=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expressed-wealth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "earned-timing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seq1': 1.1905, 'seq2': 1.3808, 'seq3': 1.0476, 'seq4': 0.3812}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh94_dict = calc_HH94(df)\n",
    "hh94_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = df[0]\n",
    "\n",
    "col_aa_frq = get_col_aa_frequencies(column, hh94_dict, background_aa_freq)\n",
    "col_aa_frq\n",
    "ngaps = col_aa_frq.popitem()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_aa_scores = aa_freq_to_score(col_aa_frq)\n",
    "bestaa,bestaascore = get_best_aa_and_score(col_aa_scores)\n",
    "print(bestaa)\n",
    "print(bestaascore)\n",
    "#col_aa_scores\n",
    "\n",
    "#weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "nseqs = 4\n",
    "print(f\"bestwt is {bestaascore}, nseqs is {nseqs}, pse is 0, bestAA is {bestaa}, bestAAexpect is {expectedAAscores[bestaa]}, blosumscore is {blosum62[bestaa,bestaa]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "if bestaascore/nseqs > expectedAAscores[bestaa]:\n",
    "    hom = calc_homogeneity(bestaa, bestaascore, nseqs, expectedAAscores, blosum62)\n",
    "print(hom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grcon = 0.499\n",
    "hocon = 0.33\n",
    "con = assign_consensus(bestaa, grcon, hom, hocon, ngaps)\n",
    "print(ngaps)\n",
    "print(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-amsterdam",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fallen-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_msa(msa, msa_out, grcut=1, hocut=-100, gcon=0.499, hcon=0.333, conplus=False, grswe=0.51):\n",
    "    \"\"\"\n",
    "    MSA filtering + trimming, as described in \n",
    "    Esterman et. al (2021) https://doi.org/10.1093/ve/veab015\n",
    "    \"\"\"\n",
    "\n",
    "    bad_cols = []\n",
    "    \n",
    "    if grcut < 1:\n",
    "        print(f'getting a list of positions that are > {grcut * 100}% gaps')\n",
    "        \n",
    "        df = fa_to_df(msa, is_msa=True)\n",
    "        \n",
    "        #get a list of gap positions\n",
    "        gapcols = get_gap_cols_from_msa(df, grcut)\n",
    "        \n",
    "        bad_cols += gapcols\n",
    "        \n",
    "        \n",
    "    if hocut >= 0 or conplus:\n",
    "        \n",
    "        #then we need to iterate through each position in the MSA\n",
    "        print(f'iterating through the alignment')\n",
    "        \n",
    "        #consensus seq is empty\n",
    "        conseq = []\n",
    "        \n",
    "        #get the necessary tables\n",
    "        background_aa_freq,blosum62,expectedAAscores = get_tables_for_msa_filtering()\n",
    "        \n",
    "        #convert the msa to a dataframe \n",
    "        df = fa_to_df(msa, is_msa=True)\n",
    "        nseqs, ncols = df.shape\n",
    "        \n",
    "        #get the HH94 scores of the sequences\n",
    "        hh94_scores = calc_HH94(df, grswe)\n",
    "        \n",
    "        for col in range(0,ncols):\n",
    "            \n",
    "            #get the column\n",
    "            column = df[col]\n",
    "\n",
    "            #calculate the AA frequencies\n",
    "            col_aa_frq = get_col_aa_frequencies(column, hh94_scores, background_aa_freq)\n",
    "\n",
    "            #the last item in the dictionary is the gap frequencies\n",
    "            #record it and remove from the dictionary,\n",
    "            #otherwise the next fxn throws an error\n",
    "            ngaps = col_aa_frq.popitem()[1]\n",
    "\n",
    "            #convert the frequencies to scores\n",
    "            col_aa_scores = aa_freq_to_score(col_aa_frq)\n",
    "\n",
    "            #get the top scoring AA\n",
    "            bestaa, bestaascore = get_best_aa_and_score(col_aa_scores)\n",
    "                \n",
    "            #assess the homogeneity of the AA, if the bestscoring AA is above expectation\n",
    "            if bestaascore/nseqs > expectedAAscores[bestaa]:\n",
    "                homo = calc_homogeneity(bestaa, bestaascore, nseqs, expectedAAscores, blosum62)\n",
    "            \n",
    "            #record columns that are below the homogeneity threshold\n",
    "            if homo < hocut:\n",
    "                bad_cols.append(col)\n",
    "\n",
    "            #assign the consensus\n",
    "            con = assign_consensus(bestaa, gcon, homo, hcon, ngaps, nseqs)\n",
    "            conseq.append(con)\n",
    "        \n",
    "        if conplus:\n",
    "            \n",
    "            #make a dataframe from the consensus\n",
    "            df_c = pd.DataFrame.from_records([conseq], index = [\"CONSENSUS\"])\n",
    "            \n",
    "            #update the original MSA datafarme\n",
    "            df = pd.concat([df_c,df])\n",
    "        \n",
    "        #remove gap/nonhomogenous columns\n",
    "        if len(bad_cols) > 0:\n",
    "            df = df.drop(columns = bad_cols)\n",
    "            \n",
    "        #write the output\n",
    "        with open(msa_out, 'w') as f:\n",
    "            df_to_fa(df, msa_out)\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    else:\n",
    "        print('doing nothing, printing alignment')\n",
    "        df = fa_to_df(msa, is_msa=True)\n",
    "        with open(msa_out, 'w') as f:\n",
    "            df_to_fa(df, msa_out)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-victory",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "conseq = filter_msa('C19_cas8b2.FASTA','test.afa', grcut=0.667, hcon=0.33, conplus=True, hocut=0.05)\n",
    "conseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statewide-brand",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-ecuador",
   "metadata": {},
   "source": [
    "- I noticed my background expect AA frequencies differ from Yuris. It turns out, his blosum62 matrix is different than mine/ For example, Yuri scores RD as -1, but mine is -2. According to [BLAST]((https://ftp.ncbi.nlm.nih.gov/blast/matrices/BLOSUM62), it is -2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(blosum62[\"R\",\"D\"])\n",
    "print(blosum62[\"R\",\"V\"])\n",
    "#print(blosum62)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-queens",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "I typically use `-hocut=0.1` for filtering the MSA prior to tree construction. \n",
    "\n",
    "Looking at `prof_align`, `-hocut` isn't invoked.\n",
    "\n",
    "Looking at `cog_psicognitor`, which invokes `run_psiprofile`, the srfilter command is (If there is consensus, don't bother filtering):\n",
    ">\"sr_filter -conplus -gcon=.499 -hcon=0 -grcut=.499\" unless(xcons)\n",
    "\n",
    "So, hocut is invoked as part of the `-hcon` command, which asserts that the minimum homogeneity of the consensus must be 0.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-tension",
   "metadata": {},
   "source": [
    "So how does Yuri calculate homogeneity?\n",
    "```\n",
    "$hom = ($bestwt/($pcnt+$pse) - $expect{$bestaa})/($simmat{$bestaa.$bestaa} - $expect{$bestaa}) if($bestaa ne \"\" and $bestwt/($nseq+$pse)>$expect{$bestaa});\n",
    "```\n",
    "\n",
    "perform the homogoneity calculation if (bestaa does not equal \"\" and bestwt/nseq+pse > expect(bestaa))\n",
    "\n",
    "\n",
    "1. bestwt = -100.0*($nseq+$pse) \n",
    "    -nseq = # of seqs in MSA\n",
    "    -pse = pseudocounts, default 0\n",
    "2. pcnt = # of seqs in MSA, adjusted if we exclude gaps (we don't, by default). So, basically just nseq.\n",
    "3.\n",
    "....?  I should just ask him."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
